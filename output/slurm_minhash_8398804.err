INFO:    Using cached SIF image
ps: invalid option -- 'p'
BusyBox v1.36.1 (2023-10-17 11:19:33 UTC) multi-call binary.

Usage: ps [-o COL1,COL2=HEADER] [-T]

Show list of processes

	-o COL1,COL2=HEADER	Select columns for display
	-T			Show threads
25/10/26 23:21:43 INFO SparkContext: Running Spark version 3.5.0
25/10/26 23:21:43 INFO SparkContext: OS info Linux, 5.14.0-503.19.1.el9_5.x86_64, amd64
25/10/26 23:21:43 INFO SparkContext: Java version 21.0.1-internal
25/10/26 23:21:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/26 23:21:43 INFO ResourceUtils: ==============================================================
25/10/26 23:21:43 INFO ResourceUtils: No custom resources configured for spark.driver.
25/10/26 23:21:43 INFO ResourceUtils: ==============================================================
25/10/26 23:21:43 INFO SparkContext: Submitted application: Protein MinHash Similarity
25/10/26 23:21:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/10/26 23:21:43 INFO ResourceProfile: Limiting resource is cpu
25/10/26 23:21:43 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/10/26 23:21:43 INFO SecurityManager: Changing view acls to: lboro
25/10/26 23:21:43 INFO SecurityManager: Changing modify acls to: lboro
25/10/26 23:21:43 INFO SecurityManager: Changing view acls groups to: 
25/10/26 23:21:43 INFO SecurityManager: Changing modify acls groups to: 
25/10/26 23:21:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: lboro; groups with view permissions: EMPTY; users with modify permissions: lboro; groups with modify permissions: EMPTY
25/10/26 23:21:43 INFO Utils: Successfully started service 'sparkDriver' on port 38289.
25/10/26 23:21:43 INFO SparkEnv: Registering MapOutputTracker
25/10/26 23:21:43 INFO SparkEnv: Registering BlockManagerMaster
25/10/26 23:21:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/10/26 23:21:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/10/26 23:21:43 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/10/26 23:21:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e731714b-e63d-4124-86f4-9a88aa5c2250
25/10/26 23:21:43 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/10/26 23:21:43 INFO SparkEnv: Registering OutputCommitCoordinator
25/10/26 23:21:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/10/26 23:21:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/10/26 23:21:44 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/10/26 23:21:44 INFO Executor: Starting executor ID driver on host t1-11.hpc.icm.edu.pl
25/10/26 23:21:44 INFO Executor: OS info Linux, 5.14.0-503.19.1.el9_5.x86_64, amd64
25/10/26 23:21:44 INFO Executor: Java version 21.0.1-internal
25/10/26 23:21:44 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/10/26 23:21:44 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6dd46fcb for default.
25/10/26 23:21:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38785.
25/10/26 23:21:44 INFO NettyBlockTransferService: Server created on t1-11.hpc.icm.edu.pl:38785
25/10/26 23:21:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/10/26 23:21:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, t1-11.hpc.icm.edu.pl, 38785, None)
25/10/26 23:21:44 INFO BlockManagerMasterEndpoint: Registering block manager t1-11.hpc.icm.edu.pl:38785 with 434.4 MiB RAM, BlockManagerId(driver, t1-11.hpc.icm.edu.pl, 38785, None)
25/10/26 23:21:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, t1-11.hpc.icm.edu.pl, 38785, None)
25/10/26 23:21:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, t1-11.hpc.icm.edu.pl, 38785, None)
25/10/26 23:21:44 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/10/26 23:21:44 INFO SharedState: Warehouse path is 'file:/lu/topola/home/lboro/omics-projekt-semestralny/spark-warehouse'.
25/10/26 23:21:45 INFO InMemoryFileIndex: It took 86 ms to list leaf files for 1 paths.
25/10/26 23:21:45 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/10/26 23:21:45 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/10/26 23:21:45 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
25/10/26 23:21:45 INFO DAGScheduler: Parents of final stage: List()
25/10/26 23:21:45 INFO DAGScheduler: Missing parents: List()
25/10/26 23:21:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/10/26 23:21:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.2 KiB, free 434.3 MiB)
25/10/26 23:21:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 434.3 MiB)
25/10/26 23:21:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 37.2 KiB, free: 434.4 MiB)
25/10/26 23:21:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
25/10/26 23:21:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/10/26 23:21:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/10/26 23:21:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, PROCESS_LOCAL, 7803 bytes) 
25/10/26 23:21:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/10/26 23:21:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2919 bytes result sent to driver
25/10/26 23:21:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 350 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/1)
25/10/26 23:21:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/10/26 23:21:46 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.476 s
25/10/26 23:21:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/10/26 23:21:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/10/26 23:21:46 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.529110 s
25/10/26 23:21:47 INFO BlockManagerInfo: Removed broadcast_0_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 37.2 KiB, free: 434.4 MiB)
25/10/26 23:21:47 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/10/26 23:21:47 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
25/10/26 23:21:47 INFO DAGScheduler: Got job 1 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/10/26 23:21:47 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0)
25/10/26 23:21:47 INFO DAGScheduler: Parents of final stage: List()
25/10/26 23:21:47 INFO DAGScheduler: Missing parents: List()
25/10/26 23:21:47 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
25/10/26 23:21:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 103.2 KiB, free 434.3 MiB)
25/10/26 23:21:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 434.3 MiB)
25/10/26 23:21:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 37.2 KiB, free: 434.4 MiB)
25/10/26 23:21:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
25/10/26 23:21:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/10/26 23:21:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/10/26 23:21:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, PROCESS_LOCAL, 7802 bytes) 
25/10/26 23:21:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/10/26 23:21:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2876 bytes result sent to driver
25/10/26 23:21:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/1)
25/10/26 23:21:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/10/26 23:21:47 INFO DAGScheduler: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.074 s
25/10/26 23:21:47 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/10/26 23:21:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/10/26 23:21:47 INFO DAGScheduler: Job 1 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.079109 s
25/10/26 23:21:47 INFO FileSourceStrategy: Pushed Filters: 
25/10/26 23:21:47 INFO FileSourceStrategy: Post-Scan Filters: 
25/10/26 23:21:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 37.2 KiB, free: 434.4 MiB)
25/10/26 23:21:47 INFO CodeGenerator: Code generated in 175.730847 ms
25/10/26 23:21:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 200.7 KiB, free 434.2 MiB)
25/10/26 23:21:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.7 KiB, free 434.2 MiB)
25/10/26 23:21:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 34.7 KiB, free: 434.4 MiB)
25/10/26 23:21:47 INFO SparkContext: Created broadcast 2 from count at NativeMethodAccessorImpl.java:0
25/10/26 23:21:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13835454 bytes, open cost is considered as scanning 4194304 bytes.
25/10/26 23:21:48 INFO DAGScheduler: Registering RDD 7 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/10/26 23:21:48 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/10/26 23:21:48 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/10/26 23:21:48 INFO DAGScheduler: Parents of final stage: List()
25/10/26 23:21:48 INFO DAGScheduler: Missing parents: List()
25/10/26 23:21:48 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.8 KiB, free 434.2 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 434.1 MiB)
25/10/26 23:21:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 7.7 KiB, free: 434.4 MiB)
25/10/26 23:21:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
25/10/26 23:21:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/10/26 23:21:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks resource profile 0
25/10/26 23:21:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, PROCESS_LOCAL, 8269 bytes) 
25/10/26 23:21:48 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (t1-11.hpc.icm.edu.pl, executor driver, partition 1, PROCESS_LOCAL, 8269 bytes) 
25/10/26 23:21:48 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (t1-11.hpc.icm.edu.pl, executor driver, partition 2, PROCESS_LOCAL, 8269 bytes) 
25/10/26 23:21:48 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (t1-11.hpc.icm.edu.pl, executor driver, partition 3, PROCESS_LOCAL, 8587 bytes) 
25/10/26 23:21:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/10/26 23:21:48 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
25/10/26 23:21:48 INFO Executor: Running task 2.0 in stage 2.0 (TID 4)
25/10/26 23:21:48 INFO Executor: Running task 3.0 in stage 2.0 (TID 5)
25/10/26 23:21:48 INFO CodeGenerator: Code generated in 13.633004 ms
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00000.gz.parquet, range: 13835454-14311938, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00002.gz.parquet, range: 0-13835454, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00001.gz.parquet, range: 0-13835454, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00000.gz.parquet, range: 0-13835454, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00001.gz.parquet, range: 13835454-14288646, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00002.gz.parquet, range: 13835454-14158322, partition values: [empty row]
25/10/26 23:21:48 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 2144 bytes result sent to driver
25/10/26 23:21:48 INFO Executor: Finished task 3.0 in stage 2.0 (TID 5). 2101 bytes result sent to driver
25/10/26 23:21:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2187 bytes result sent to driver
25/10/26 23:21:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 2187 bytes result sent to driver
25/10/26 23:21:48 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 180 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/4)
25/10/26 23:21:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 181 ms on t1-11.hpc.icm.edu.pl (executor driver) (2/4)
25/10/26 23:21:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 185 ms on t1-11.hpc.icm.edu.pl (executor driver) (3/4)
25/10/26 23:21:48 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 187 ms on t1-11.hpc.icm.edu.pl (executor driver) (4/4)
25/10/26 23:21:48 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.233 s
25/10/26 23:21:48 INFO DAGScheduler: looking for newly runnable stages
25/10/26 23:21:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/10/26 23:21:48 INFO DAGScheduler: running: Set()
25/10/26 23:21:48 INFO DAGScheduler: waiting: Set()
25/10/26 23:21:48 INFO DAGScheduler: failed: Set()
25/10/26 23:21:48 INFO CodeGenerator: Code generated in 10.286338 ms
25/10/26 23:21:48 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/10/26 23:21:48 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/10/26 23:21:48 INFO DAGScheduler: Final stage: ResultStage 4 (count at NativeMethodAccessorImpl.java:0)
25/10/26 23:21:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/10/26 23:21:48 INFO DAGScheduler: Missing parents: List()
25/10/26 23:21:48 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
25/10/26 23:21:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 5.9 KiB, free: 434.4 MiB)
25/10/26 23:21:48 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
25/10/26 23:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/10/26 23:21:48 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/10/26 23:21:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, NODE_LOCAL, 7615 bytes) 
25/10/26 23:21:48 INFO Executor: Running task 0.0 in stage 4.0 (TID 6)
25/10/26 23:21:48 INFO BlockManagerInfo: Removed broadcast_3_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 7.7 KiB, free: 434.4 MiB)
25/10/26 23:21:48 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:21:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
25/10/26 23:21:48 INFO CodeGenerator: Code generated in 9.534884 ms
25/10/26 23:21:48 INFO Executor: Finished task 0.0 in stage 4.0 (TID 6). 4081 bytes result sent to driver
25/10/26 23:21:48 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 75 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/1)
25/10/26 23:21:48 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/10/26 23:21:48 INFO DAGScheduler: ResultStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.086 s
25/10/26 23:21:48 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/10/26 23:21:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/10/26 23:21:48 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.097791 s
25/10/26 23:21:48 INFO FileSourceStrategy: Pushed Filters: 
25/10/26 23:21:48 INFO FileSourceStrategy: Post-Scan Filters: 
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 200.7 KiB, free 434.0 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 34.7 KiB, free 433.9 MiB)
25/10/26 23:21:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 34.7 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/10/26 23:21:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13002480 bytes, open cost is considered as scanning 4194304 bytes.
25/10/26 23:21:48 INFO DAGScheduler: Registering RDD 14 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/10/26 23:21:48 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/10/26 23:21:48 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/10/26 23:21:48 INFO DAGScheduler: Parents of final stage: List()
25/10/26 23:21:48 INFO DAGScheduler: Missing parents: List()
25/10/26 23:21:48 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.8 KiB, free 433.9 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 433.9 MiB)
25/10/26 23:21:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 7.7 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
25/10/26 23:21:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/10/26 23:21:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks resource profile 0
25/10/26 23:21:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes) 
25/10/26 23:21:48 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8) (t1-11.hpc.icm.edu.pl, executor driver, partition 1, PROCESS_LOCAL, 8268 bytes) 
25/10/26 23:21:48 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 9) (t1-11.hpc.icm.edu.pl, executor driver, partition 2, PROCESS_LOCAL, 8268 bytes) 
25/10/26 23:21:48 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 10) (t1-11.hpc.icm.edu.pl, executor driver, partition 3, PROCESS_LOCAL, 8584 bytes) 
25/10/26 23:21:48 INFO Executor: Running task 0.0 in stage 5.0 (TID 7)
25/10/26 23:21:48 INFO Executor: Running task 1.0 in stage 5.0 (TID 8)
25/10/26 23:21:48 INFO Executor: Running task 2.0 in stage 5.0 (TID 9)
25/10/26 23:21:48 INFO Executor: Running task 3.0 in stage 5.0 (TID 10)
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00000.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00002.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00002.gz.parquet, range: 13002480-13172102, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00001.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00000.gz.parquet, range: 13002480-13149302, partition values: [empty row]
25/10/26 23:21:48 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00001.gz.parquet, range: 13002480-13105606, partition values: [empty row]
25/10/26 23:21:48 INFO Executor: Finished task 2.0 in stage 5.0 (TID 9). 2144 bytes result sent to driver
25/10/26 23:21:48 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 9) in 41 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/4)
25/10/26 23:21:48 INFO Executor: Finished task 1.0 in stage 5.0 (TID 8). 2144 bytes result sent to driver
25/10/26 23:21:48 INFO Executor: Finished task 3.0 in stage 5.0 (TID 10). 2101 bytes result sent to driver
25/10/26 23:21:48 INFO Executor: Finished task 0.0 in stage 5.0 (TID 7). 2144 bytes result sent to driver
25/10/26 23:21:48 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 45 ms on t1-11.hpc.icm.edu.pl (executor driver) (2/4)
25/10/26 23:21:48 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 47 ms on t1-11.hpc.icm.edu.pl (executor driver) (3/4)
25/10/26 23:21:48 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 10) in 46 ms on t1-11.hpc.icm.edu.pl (executor driver) (4/4)
25/10/26 23:21:48 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/10/26 23:21:48 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.055 s
25/10/26 23:21:48 INFO DAGScheduler: looking for newly runnable stages
25/10/26 23:21:48 INFO DAGScheduler: running: Set()
25/10/26 23:21:48 INFO DAGScheduler: waiting: Set()
25/10/26 23:21:48 INFO DAGScheduler: failed: Set()
25/10/26 23:21:48 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/10/26 23:21:48 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/10/26 23:21:48 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/10/26 23:21:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/10/26 23:21:48 INFO DAGScheduler: Missing parents: List()
25/10/26 23:21:48 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)
25/10/26 23:21:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 5.9 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
25/10/26 23:21:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/10/26 23:21:48 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/10/26 23:21:48 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 11) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, NODE_LOCAL, 7615 bytes) 
25/10/26 23:21:48 INFO Executor: Running task 0.0 in stage 7.0 (TID 11)
25/10/26 23:21:48 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:21:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/10/26 23:21:48 INFO Executor: Finished task 0.0 in stage 7.0 (TID 11). 3995 bytes result sent to driver
25/10/26 23:21:48 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 11) in 10 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/1)
25/10/26 23:21:48 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/10/26 23:21:48 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.018 s
25/10/26 23:21:48 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/10/26 23:21:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/10/26 23:21:48 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.020931 s
25/10/26 23:21:48 INFO FileSourceStrategy: Pushed Filters: 
25/10/26 23:21:48 INFO FileSourceStrategy: Post-Scan Filters: 
25/10/26 23:21:48 INFO FileSourceStrategy: Pushed Filters: 
25/10/26 23:21:48 INFO FileSourceStrategy: Post-Scan Filters: 
25/10/26 23:21:48 INFO CodeGenerator: Code generated in 12.440564 ms
25/10/26 23:21:48 INFO CodeGenerator: Code generated in 15.099888 ms
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 200.8 KiB, free 433.7 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
25/10/26 23:21:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 34.9 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO SparkContext: Created broadcast 8 from javaToPython at NativeMethodAccessorImpl.java:0
25/10/26 23:21:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13835454 bytes, open cost is considered as scanning 4194304 bytes.
25/10/26 23:21:48 INFO CodeGenerator: Code generated in 15.938317 ms
25/10/26 23:21:48 INFO BlockManagerInfo: Removed broadcast_7_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 5.9 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO CodeGenerator: Code generated in 10.868116 ms
25/10/26 23:21:48 INFO BlockManagerInfo: Removed broadcast_5_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 34.7 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 200.8 KiB, free 433.5 MiB)
25/10/26 23:21:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
25/10/26 23:21:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 34.9 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO SparkContext: Created broadcast 9 from javaToPython at NativeMethodAccessorImpl.java:0
25/10/26 23:21:48 INFO BlockManagerInfo: Removed broadcast_4_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 5.9 KiB, free: 434.3 MiB)
25/10/26 23:21:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13002480 bytes, open cost is considered as scanning 4194304 bytes.
25/10/26 23:21:48 INFO BlockManagerInfo: Removed broadcast_6_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 7.7 KiB, free: 434.3 MiB)
25/10/26 23:21:49 INFO SparkContext: Starting job: collect at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93
25/10/26 23:21:49 INFO DAGScheduler: Registering RDD 35 (distinct at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93) as input to shuffle 2
25/10/26 23:21:49 INFO DAGScheduler: Got job 6 (collect at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93) with 8 output partitions
25/10/26 23:21:49 INFO DAGScheduler: Final stage: ResultStage 9 (collect at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93)
25/10/26 23:21:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/10/26 23:21:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
25/10/26 23:21:49 INFO DAGScheduler: Submitting ShuffleMapStage 8 (PairwiseRDD[35] at distinct at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93), which has no missing parents
25/10/26 23:21:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 51.8 KiB, free 433.7 MiB)
25/10/26 23:21:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 433.6 MiB)
25/10/26 23:21:49 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 23.2 KiB, free: 434.3 MiB)
25/10/26 23:21:49 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
25/10/26 23:21:49 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 8 (PairwiseRDD[35] at distinct at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/10/26 23:21:49 INFO TaskSchedulerImpl: Adding task set 8.0 with 8 tasks resource profile 0
25/10/26 23:21:49 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 12) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, PROCESS_LOCAL, 8378 bytes) 
25/10/26 23:21:49 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 13) (t1-11.hpc.icm.edu.pl, executor driver, partition 1, PROCESS_LOCAL, 8378 bytes) 
25/10/26 23:21:49 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 14) (t1-11.hpc.icm.edu.pl, executor driver, partition 2, PROCESS_LOCAL, 8378 bytes) 
25/10/26 23:21:49 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 15) (t1-11.hpc.icm.edu.pl, executor driver, partition 3, PROCESS_LOCAL, 8696 bytes) 
25/10/26 23:21:49 INFO Executor: Running task 0.0 in stage 8.0 (TID 12)
25/10/26 23:21:49 INFO Executor: Running task 2.0 in stage 8.0 (TID 14)
25/10/26 23:21:49 INFO Executor: Running task 1.0 in stage 8.0 (TID 13)
25/10/26 23:21:49 INFO Executor: Running task 3.0 in stage 8.0 (TID 15)
25/10/26 23:21:49 INFO CodeGenerator: Code generated in 11.0584 ms
25/10/26 23:21:49 INFO CodeGenerator: Code generated in 10.034116 ms
25/10/26 23:21:49 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00002.gz.parquet, range: 0-13835454, partition values: [empty row]
25/10/26 23:21:49 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00000.gz.parquet, range: 13835454-14311938, partition values: [empty row]
25/10/26 23:21:49 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00000.gz.parquet, range: 0-13835454, partition values: [empty row]
25/10/26 23:21:49 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00001.gz.parquet, range: 0-13835454, partition values: [empty row]
25/10/26 23:21:49 INFO CodeGenerator: Code generated in 38.246575 ms
25/10/26 23:21:49 INFO CodeGenerator: Code generated in 19.493888 ms
25/10/26 23:21:49 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00001.gz.parquet, range: 13835454-14288646, partition values: [empty row]
25/10/26 23:21:49 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00002.gz.parquet, range: 13835454-14158322, partition values: [empty row]
25/10/26 23:21:50 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:21:50 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:21:50 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:21:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 34.7 KiB, free: 434.3 MiB)
25/10/26 23:21:50 INFO PythonUDFRunner: Times: total = 868, boot = 720, init = 148, finish = 0
25/10/26 23:21:51 INFO PythonRunner: Times: total = 1154, boot = 958, init = 195, finish = 1
25/10/26 23:21:51 INFO Executor: Finished task 3.0 in stage 8.0 (TID 15). 3262 bytes result sent to driver
25/10/26 23:21:51 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 16) (t1-11.hpc.icm.edu.pl, executor driver, partition 4, PROCESS_LOCAL, 8377 bytes) 
25/10/26 23:21:51 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 15) in 2020 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/8)
25/10/26 23:21:51 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 57901
25/10/26 23:21:51 INFO Executor: Running task 4.0 in stage 8.0 (TID 16)
25/10/26 23:21:51 INFO CodeGenerator: Code generated in 27.455307 ms
25/10/26 23:21:51 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00000.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:21:51 INFO CodeGenerator: Code generated in 20.554112 ms
25/10/26 23:21:51 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:21:57 INFO PythonUDFRunner: Times: total = 2597, boot = -1117, init = 1274, finish = 2440
25/10/26 23:21:57 INFO PythonUDFRunner: Times: total = 6055, boot = 716, init = 429, finish = 4910
25/10/26 23:21:57 INFO PythonUDFRunner: Times: total = 5610, boot = 712, init = 442, finish = 4456
25/10/26 23:21:57 INFO PythonUDFRunner: Times: total = 5326, boot = 722, init = 423, finish = 4181
25/10/26 23:21:58 INFO PythonRunner: Times: total = 7943, boot = 916, init = 298, finish = 6729
25/10/26 23:21:58 INFO Executor: Finished task 0.0 in stage 8.0 (TID 12). 3477 bytes result sent to driver
25/10/26 23:21:58 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 17) (t1-11.hpc.icm.edu.pl, executor driver, partition 5, PROCESS_LOCAL, 8377 bytes) 
25/10/26 23:21:58 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 12) in 8943 ms on t1-11.hpc.icm.edu.pl (executor driver) (2/8)
25/10/26 23:21:58 INFO Executor: Running task 5.0 in stage 8.0 (TID 17)
25/10/26 23:21:58 INFO PythonRunner: Times: total = 7898, boot = 913, init = 314, finish = 6671
25/10/26 23:21:58 INFO Executor: Finished task 1.0 in stage 8.0 (TID 13). 3477 bytes result sent to driver
25/10/26 23:21:58 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 18) (t1-11.hpc.icm.edu.pl, executor driver, partition 6, PROCESS_LOCAL, 8377 bytes) 
25/10/26 23:21:58 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 13) in 8969 ms on t1-11.hpc.icm.edu.pl (executor driver) (3/8)
25/10/26 23:21:58 INFO Executor: Running task 6.0 in stage 8.0 (TID 18)
25/10/26 23:21:58 INFO PythonRunner: Times: total = 6262, boot = -24, init = 211, finish = 6075
25/10/26 23:21:58 INFO Executor: Finished task 4.0 in stage 8.0 (TID 16). 3477 bytes result sent to driver
25/10/26 23:21:58 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 19) (t1-11.hpc.icm.edu.pl, executor driver, partition 7, PROCESS_LOCAL, 8693 bytes) 
25/10/26 23:21:58 INFO Executor: Running task 7.0 in stage 8.0 (TID 19)
25/10/26 23:21:58 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 16) in 6959 ms on t1-11.hpc.icm.edu.pl (executor driver) (4/8)
25/10/26 23:21:58 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00002.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:21:58 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00001.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:21:58 INFO PythonRunner: Times: total = 8097, boot = 969, init = 245, finish = 6883
25/10/26 23:21:58 INFO Executor: Finished task 2.0 in stage 8.0 (TID 14). 3477 bytes result sent to driver
25/10/26 23:21:58 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 14) in 9005 ms on t1-11.hpc.icm.edu.pl (executor driver) (5/8)
25/10/26 23:21:58 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:21:58 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:21:58 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00002.gz.parquet, range: 13002480-13172102, partition values: [empty row]
25/10/26 23:21:58 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00000.gz.parquet, range: 13002480-13149302, partition values: [empty row]
25/10/26 23:21:58 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00001.gz.parquet, range: 13002480-13105606, partition values: [empty row]
25/10/26 23:21:58 INFO PythonUDFRunner: Times: total = 291, boot = -3274, init = 3565, finish = 0
25/10/26 23:21:58 INFO PythonRunner: Times: total = 223, boot = -717, init = 940, finish = 0
25/10/26 23:21:58 INFO Executor: Finished task 7.0 in stage 8.0 (TID 19). 3262 bytes result sent to driver
25/10/26 23:21:58 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 19) in 406 ms on t1-11.hpc.icm.edu.pl (executor driver) (6/8)
25/10/26 23:22:00 INFO PythonUDFRunner: Times: total = 1311, boot = -2834, init = 2950, finish = 1195
25/10/26 23:22:01 INFO PythonUDFRunner: Times: total = 1251, boot = -4280, init = 4462, finish = 1069
25/10/26 23:22:01 INFO PythonRunner: Times: total = 3009, boot = -262, init = 526, finish = 2745
25/10/26 23:22:01 INFO Executor: Finished task 6.0 in stage 8.0 (TID 18). 3477 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 18) in 3144 ms on t1-11.hpc.icm.edu.pl (executor driver) (7/8)
25/10/26 23:22:01 INFO PythonRunner: Times: total = 3272, boot = -168, init = 381, finish = 3059
25/10/26 23:22:01 INFO Executor: Finished task 5.0 in stage 8.0 (TID 17). 3477 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 17) in 3356 ms on t1-11.hpc.icm.edu.pl (executor driver) (8/8)
25/10/26 23:22:01 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/10/26 23:22:01 INFO DAGScheduler: ShuffleMapStage 8 (distinct at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93) finished in 12.314 s
25/10/26 23:22:01 INFO DAGScheduler: looking for newly runnable stages
25/10/26 23:22:01 INFO DAGScheduler: running: Set()
25/10/26 23:22:01 INFO DAGScheduler: waiting: Set(ResultStage 9)
25/10/26 23:22:01 INFO DAGScheduler: failed: Set()
25/10/26 23:22:01 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[38] at collect at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93), which has no missing parents
25/10/26 23:22:01 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.7 KiB, free 433.9 MiB)
25/10/26 23:22:01 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 433.8 MiB)
25/10/26 23:22:01 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 6.3 KiB, free: 434.3 MiB)
25/10/26 23:22:01 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
25/10/26 23:22:01 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 9 (PythonRDD[38] at collect at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/10/26 23:22:01 INFO TaskSchedulerImpl: Adding task set 9.0 with 8 tasks resource profile 0
25/10/26 23:22:01 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 20) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 21) (t1-11.hpc.icm.edu.pl, executor driver, partition 1, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 22) (t1-11.hpc.icm.edu.pl, executor driver, partition 2, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 23) (t1-11.hpc.icm.edu.pl, executor driver, partition 3, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 INFO Executor: Running task 2.0 in stage 9.0 (TID 22)
25/10/26 23:22:01 INFO Executor: Running task 3.0 in stage 9.0 (TID 23)
25/10/26 23:22:01 INFO Executor: Running task 0.0 in stage 9.0 (TID 20)
25/10/26 23:22:01 INFO Executor: Running task 1.0 in stage 9.0 (TID 21)
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/10/26 23:22:01 INFO PythonRunner: Times: total = 104, boot = -270, init = 367, finish = 7
25/10/26 23:22:01 INFO PythonRunner: Times: total = 108, boot = -2911, init = 3014, finish = 5
25/10/26 23:22:01 INFO Executor: Finished task 1.0 in stage 9.0 (TID 21). 8388 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 24) (t1-11.hpc.icm.edu.pl, executor driver, partition 4, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors
25/10/26 23:22:01 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 21) in 128 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/8)
25/10/26 23:22:01 INFO Executor: Finished task 3.0 in stage 9.0 (TID 23). 8699 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 25) (t1-11.hpc.icm.edu.pl, executor driver, partition 5, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 23) in 131 ms on t1-11.hpc.icm.edu.pl (executor driver) (2/8)
25/10/26 23:22:01 INFO Executor: Running task 5.0 in stage 9.0 (TID 25)
25/10/26 23:22:01 INFO Executor: Running task 4.0 in stage 9.0 (TID 24)
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/10/26 23:22:01 INFO PythonRunner: Times: total = 165, boot = -3340, init = 3501, finish = 4
25/10/26 23:22:01 INFO Executor: Finished task 2.0 in stage 9.0 (TID 22). 8322 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 26) (t1-11.hpc.icm.edu.pl, executor driver, partition 6, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 22) in 184 ms on t1-11.hpc.icm.edu.pl (executor driver) (3/8)
25/10/26 23:22:01 INFO Executor: Running task 6.0 in stage 9.0 (TID 26)
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/10/26 23:22:01 INFO PythonRunner: Times: total = 206, boot = -58, init = 259, finish = 5
25/10/26 23:22:01 INFO Executor: Finished task 0.0 in stage 9.0 (TID 20). 8573 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 27) (t1-11.hpc.icm.edu.pl, executor driver, partition 7, NODE_LOCAL, 7433 bytes) 
25/10/26 23:22:01 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 20) in 234 ms on t1-11.hpc.icm.edu.pl (executor driver) (4/8)
25/10/26 23:22:01 INFO Executor: Running task 7.0 in stage 9.0 (TID 27)
25/10/26 23:22:01 INFO PythonRunner: Times: total = 95, boot = 23, init = 67, finish = 5
25/10/26 23:22:01 INFO Executor: Finished task 4.0 in stage 9.0 (TID 24). 8214 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 24) in 114 ms on t1-11.hpc.icm.edu.pl (executor driver) (5/8)
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Getting 6 (28.3 KiB) non-empty blocks including 6 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/10/26 23:22:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/10/26 23:22:01 INFO PythonRunner: Times: total = 141, boot = 14, init = 123, finish = 4
25/10/26 23:22:01 INFO Executor: Finished task 5.0 in stage 9.0 (TID 25). 8585 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 25) in 153 ms on t1-11.hpc.icm.edu.pl (executor driver) (6/8)
25/10/26 23:22:01 INFO PythonRunner: Times: total = 124, boot = 29, init = 91, finish = 4
25/10/26 23:22:01 INFO Executor: Finished task 6.0 in stage 9.0 (TID 26). 8621 bytes result sent to driver
25/10/26 23:22:01 INFO PythonRunner: Times: total = 73, boot = 8, init = 61, finish = 4
25/10/26 23:22:01 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 26) in 140 ms on t1-11.hpc.icm.edu.pl (executor driver) (7/8)
25/10/26 23:22:01 INFO Executor: Finished task 7.0 in stage 9.0 (TID 27). 8352 bytes result sent to driver
25/10/26 23:22:01 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 27) in 101 ms on t1-11.hpc.icm.edu.pl (executor driver) (8/8)
25/10/26 23:22:01 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/10/26 23:22:01 INFO DAGScheduler: ResultStage 9 (collect at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93) finished in 0.340 s
25/10/26 23:22:01 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/10/26 23:22:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/10/26 23:22:01 INFO DAGScheduler: Job 6 finished: collect at /lu/topola/home/lboro/omics-projekt-semestralny/minhash.py:93, took 12.666009 s
25/10/26 23:22:01 INFO FileSourceStrategy: Pushed Filters: 
25/10/26 23:22:01 INFO FileSourceStrategy: Post-Scan Filters: 
25/10/26 23:22:01 INFO CodeGenerator: Code generated in 12.095241 ms
25/10/26 23:22:01 INFO CodeGenerator: Code generated in 9.799641 ms
25/10/26 23:22:01 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 200.8 KiB, free 433.7 MiB)
25/10/26 23:22:01 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.6 MiB)
25/10/26 23:22:01 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 34.9 KiB, free: 434.3 MiB)
25/10/26 23:22:01 INFO SparkContext: Created broadcast 12 from head at DatasetUtils.scala:218
25/10/26 23:22:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13835454 bytes, open cost is considered as scanning 4194304 bytes.
25/10/26 23:22:01 INFO SparkContext: Starting job: head at DatasetUtils.scala:218
25/10/26 23:22:01 INFO DAGScheduler: Got job 7 (head at DatasetUtils.scala:218) with 1 output partitions
25/10/26 23:22:01 INFO DAGScheduler: Final stage: ResultStage 10 (head at DatasetUtils.scala:218)
25/10/26 23:22:01 INFO DAGScheduler: Parents of final stage: List()
25/10/26 23:22:01 INFO DAGScheduler: Missing parents: List()
25/10/26 23:22:01 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at head at DatasetUtils.scala:218), which has no missing parents
25/10/26 23:22:01 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 106.6 KiB, free 433.5 MiB)
25/10/26 23:22:01 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 74.9 KiB, free 433.4 MiB)
25/10/26 23:22:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 74.9 KiB, free: 434.2 MiB)
25/10/26 23:22:01 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
25/10/26 23:22:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at head at DatasetUtils.scala:218) (first 15 tasks are for partitions Vector(0))
25/10/26 23:22:01 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/10/26 23:22:01 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 28) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, PROCESS_LOCAL, 8280 bytes) 
25/10/26 23:22:01 INFO Executor: Running task 0.0 in stage 10.0 (TID 28)
25/10/26 23:22:01 INFO CodeGenerator: Code generated in 8.642854 ms
25/10/26 23:22:01 INFO CodeGenerator: Code generated in 20.546477 ms
25/10/26 23:22:01 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/danio_protein.adam/part-r-00000.gz.parquet, range: 0-13835454, partition values: [empty row]
25/10/26 23:22:02 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:22:02 INFO CodeGenerator: Code generated in 24.21295 ms
25/10/26 23:22:02 INFO Executor: Finished task 0.0 in stage 10.0 (TID 28). 7471 bytes result sent to driver
25/10/26 23:22:02 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 28) in 554 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/1)
25/10/26 23:22:02 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/10/26 23:22:02 INFO DAGScheduler: ResultStage 10 (head at DatasetUtils.scala:218) finished in 0.561 s
25/10/26 23:22:02 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/10/26 23:22:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/10/26 23:22:02 INFO DAGScheduler: Job 7 finished: head at DatasetUtils.scala:218, took 0.565492 s
25/10/26 23:22:02 INFO BlockManagerInfo: Removed broadcast_11_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 6.3 KiB, free: 434.2 MiB)
25/10/26 23:22:02 INFO BlockManagerInfo: Removed broadcast_13_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 74.9 KiB, free: 434.3 MiB)
25/10/26 23:22:03 INFO CodeGenerator: Code generated in 7.267627 ms
25/10/26 23:22:03 INFO FileSourceStrategy: Pushed Filters: 
25/10/26 23:22:03 INFO FileSourceStrategy: Post-Scan Filters: 
25/10/26 23:22:03 INFO FileSourceStrategy: Pushed Filters: 
25/10/26 23:22:03 INFO FileSourceStrategy: Post-Scan Filters: 
25/10/26 23:22:03 INFO CodeGenerator: Code generated in 70.332139 ms
25/10/26 23:22:03 INFO CodeGenerator: Code generated in 12.913324 ms
25/10/26 23:22:03 INFO CodeGenerator: Code generated in 8.806573 ms
25/10/26 23:22:03 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 200.9 KiB, free 433.4 MiB)
25/10/26 23:22:03 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 433.4 MiB)
25/10/26 23:22:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 35.0 KiB, free: 434.2 MiB)
25/10/26 23:22:03 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:317
25/10/26 23:22:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13002480 bytes, open cost is considered as scanning 4194304 bytes.
25/10/26 23:22:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:317
25/10/26 23:22:04 INFO DAGScheduler: Got job 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:317) with 4 output partitions
25/10/26 23:22:04 INFO DAGScheduler: Final stage: ResultStage 11 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:317)
25/10/26 23:22:04 INFO DAGScheduler: Parents of final stage: List()
25/10/26 23:22:04 INFO DAGScheduler: Missing parents: List()
25/10/26 23:22:04 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[55] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:317), which has no missing parents
25/10/26 23:22:04 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 171.0 KiB, free 433.2 MiB)
25/10/26 23:22:04 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 92.6 KiB, free 433.1 MiB)
25/10/26 23:22:04 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 92.6 KiB, free: 434.2 MiB)
25/10/26 23:22:04 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
25/10/26 23:22:04 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[55] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:317) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/10/26 23:22:04 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks resource profile 0
25/10/26 23:22:04 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 29) (t1-11.hpc.icm.edu.pl, executor driver, partition 0, PROCESS_LOCAL, 8279 bytes) 
25/10/26 23:22:04 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 30) (t1-11.hpc.icm.edu.pl, executor driver, partition 1, PROCESS_LOCAL, 8279 bytes) 
25/10/26 23:22:04 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 31) (t1-11.hpc.icm.edu.pl, executor driver, partition 2, PROCESS_LOCAL, 8279 bytes) 
25/10/26 23:22:04 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 32) (t1-11.hpc.icm.edu.pl, executor driver, partition 3, PROCESS_LOCAL, 8595 bytes) 
25/10/26 23:22:04 INFO Executor: Running task 1.0 in stage 11.0 (TID 30)
25/10/26 23:22:04 INFO Executor: Running task 3.0 in stage 11.0 (TID 32)
25/10/26 23:22:04 INFO Executor: Running task 0.0 in stage 11.0 (TID 29)
25/10/26 23:22:04 INFO Executor: Running task 2.0 in stage 11.0 (TID 31)
25/10/26 23:22:04 INFO CodeGenerator: Code generated in 10.384837 ms
25/10/26 23:22:04 INFO CodeGenerator: Code generated in 4.559997 ms
25/10/26 23:22:04 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00002.gz.parquet, range: 13002480-13172102, partition values: [empty row]
25/10/26 23:22:04 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00000.gz.parquet, range: 13002480-13149302, partition values: [empty row]
25/10/26 23:22:04 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00001.gz.parquet, range: 13002480-13105606, partition values: [empty row]
25/10/26 23:22:04 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00002.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:22:04 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00000.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:22:04 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:22:04 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:22:04 INFO CodeGenerator: Code generated in 8.419433 ms
25/10/26 23:22:04 INFO CodeGenerator: Code generated in 14.014715 ms
25/10/26 23:22:04 INFO FileScanRDD: Reading File path: file:///lu/topola/home/lboro/omics-projekt-semestralny/data/mysz_protein.adam/part-r-00001.gz.parquet, range: 0-13002480, partition values: [empty row]
25/10/26 23:22:04 INFO CodeGenerator: Code generated in 14.280382 ms
25/10/26 23:22:04 INFO CodecPool: Got brand-new decompressor [.gz]
25/10/26 23:22:04 INFO CodeGenerator: Code generated in 199.457109 ms
25/10/26 23:22:05 INFO PythonUDFRunner: Times: total = 1237, boot = -5714, init = 6951, finish = 0
25/10/26 23:22:05 INFO CodeGenerator: Code generated in 20.484744 ms
25/10/26 23:22:05 INFO PythonUDFRunner: Times: total = 1460, boot = 7, init = 1453, finish = 0
25/10/26 23:22:05 INFO Executor: Finished task 3.0 in stage 11.0 (TID 32). 3060 bytes result sent to driver
25/10/26 23:22:05 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 32) in 1625 ms on t1-11.hpc.icm.edu.pl (executor driver) (1/4)
25/10/26 23:22:05 INFO CodeGenerator: Code generated in 47.512822 ms
25/10/26 23:22:07 INFO BlockManagerInfo: Removed broadcast_12_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 34.9 KiB, free: 434.2 MiB)
25/10/26 23:22:07 INFO BlockManagerInfo: Removed broadcast_10_piece0 on t1-11.hpc.icm.edu.pl:38785 in memory (size: 23.2 KiB, free: 434.2 MiB)
25/10/26 23:22:12 INFO PythonUDFRunner: Times: total = 6377, boot = -4767, init = 6266, finish = 4878
25/10/26 23:22:12 INFO PythonUDFRunner: Times: total = 7576, boot = -4704, init = 6080, finish = 6200
25/10/26 23:22:12 INFO PythonUDFRunner: Times: total = 7308, boot = 5, init = 1624, finish = 5679
25/10/26 23:22:13 INFO PythonUDFRunner: Times: total = 8488, boot = 22, init = 1519, finish = 6947
25/10/26 23:22:14 ERROR Executor: Exception in task 1.0 in stage 11.0 (TID 30)
java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Double.valueOf(Double.java:773)
	at net.razorvine.pickle.Unpickler.load_binfloat(Unpickler.java:478)
	at net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:277)
	at net.razorvine.pickle.Unpickler.load(Unpickler.java:109)
	at net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$2(BatchEvalPythonExec.scala:67)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec$$Lambda/0x000014a200e96830.apply(Unknown Source)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.sql.execution.SparkPlan$$Lambda/0x000014a200ddc000.apply(Unknown Source)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.RDD$$Lambda/0x000014a200d4ee28.apply(Unknown Source)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000014a200911ff0.apply(Unknown Source)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
25/10/26 23:22:14 INFO MemoryStore: Block taskresult_31 stored as bytes in memory (estimated size 99.8 MiB, free 325.7 MiB)
25/10/26 23:22:14 INFO BlockManagerInfo: Added taskresult_31 in memory on t1-11.hpc.icm.edu.pl:38785 (size: 99.8 MiB, free: 334.4 MiB)
25/10/26 23:22:14 INFO Executor: Finished task 2.0 in stage 11.0 (TID 31). 104623535 bytes result sent via BlockManager)
25/10/26 23:22:14 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[#93,Executor task launch worker for task 1.0 in stage 11.0 (TID 30),5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Double.valueOf(Double.java:773)
	at net.razorvine.pickle.Unpickler.load_binfloat(Unpickler.java:478)
	at net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:277)
	at net.razorvine.pickle.Unpickler.load(Unpickler.java:109)
	at net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$2(BatchEvalPythonExec.scala:67)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec$$Lambda/0x000014a200e96830.apply(Unknown Source)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.sql.execution.SparkPlan$$Lambda/0x000014a200ddc000.apply(Unknown Source)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.RDD$$Lambda/0x000014a200d4ee28.apply(Unknown Source)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000014a200911ff0.apply(Unknown Source)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
25/10/26 23:22:14 WARN TaskSetManager: Lost task 1.0 in stage 11.0 (TID 30) (t1-11.hpc.icm.edu.pl executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Double.valueOf(Double.java:773)
	at net.razorvine.pickle.Unpickler.load_binfloat(Unpickler.java:478)
	at net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:277)
	at net.razorvine.pickle.Unpickler.load(Unpickler.java:109)
	at net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$2(BatchEvalPythonExec.scala:67)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec$$Lambda/0x000014a200e96830.apply(Unknown Source)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.sql.execution.SparkPlan$$Lambda/0x000014a200ddc000.apply(Unknown Source)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.RDD$$Lambda/0x000014a200d4ee28.apply(Unknown Source)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000014a200911ff0.apply(Unknown Source)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)

25/10/26 23:22:14 ERROR TaskSetManager: Task 1 in stage 11.0 failed 1 times; aborting job
25/10/26 23:22:14 INFO TaskSchedulerImpl: Cancelling stage 11
25/10/26 23:22:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage cancelled: Job aborted due to stage failure: Task 1 in stage 11.0 failed 1 times, most recent failure: Lost task 1.0 in stage 11.0 (TID 30) (t1-11.hpc.icm.edu.pl executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Double.valueOf(Double.java:773)
	at net.razorvine.pickle.Unpickler.load_binfloat(Unpickler.java:478)
	at net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:277)
	at net.razorvine.pickle.Unpickler.load(Unpickler.java:109)
	at net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$2(BatchEvalPythonExec.scala:67)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec$$Lambda/0x000014a200e96830.apply(Unknown Source)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.sql.execution.SparkPlan$$Lambda/0x000014a200ddc000.apply(Unknown Source)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.RDD$$Lambda/0x000014a200d4ee28.apply(Unknown Source)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000014a200911ff0.apply(Unknown Source)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)

Driver stacktrace:
25/10/26 23:22:14 INFO SparkContext: Invoking stop() from shutdown hook
25/10/26 23:22:14 INFO Executor: Executor is trying to kill task 0.0 in stage 11.0 (TID 29), reason: Stage cancelled: Job aborted due to stage failure: Task 1 in stage 11.0 failed 1 times, most recent failure: Lost task 1.0 in stage 11.0 (TID 30) (t1-11.hpc.icm.edu.pl executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Double.valueOf(Double.java:773)
	at net.razorvine.pickle.Unpickler.load_binfloat(Unpickler.java:478)
	at net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:277)
	at net.razorvine.pickle.Unpickler.load(Unpickler.java:109)
	at net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$2(BatchEvalPythonExec.scala:67)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec$$Lambda/0x000014a200e96830.apply(Unknown Source)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.sql.execution.SparkPlan$$Lambda/0x000014a200ddc000.apply(Unknown Source)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.RDD$$Lambda/0x000014a200d4ee28.apply(Unknown Source)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000014a200911ff0.apply(Unknown Source)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)

Driver stacktrace:
25/10/26 23:22:14 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/10/26 23:22:14 INFO TaskSchedulerImpl: Stage 11 was cancelled
25/10/26 23:22:14 INFO DAGScheduler: ResultStage 11 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:317) failed in 10.548 s due to Job aborted due to stage failure: Task 1 in stage 11.0 failed 1 times, most recent failure: Lost task 1.0 in stage 11.0 (TID 30) (t1-11.hpc.icm.edu.pl executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Double.valueOf(Double.java:773)
	at net.razorvine.pickle.Unpickler.load_binfloat(Unpickler.java:478)
	at net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:277)
	at net.razorvine.pickle.Unpickler.load(Unpickler.java:109)
	at net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$2(BatchEvalPythonExec.scala:67)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec$$Lambda/0x000014a200e96830.apply(Unknown Source)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.sql.execution.SparkPlan$$Lambda/0x000014a200ddc000.apply(Unknown Source)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.RDD$$Lambda/0x000014a200d4ee28.apply(Unknown Source)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000014a200911ff0.apply(Unknown Source)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)

Driver stacktrace:
25/10/26 23:22:14 INFO DAGScheduler: Job 8 failed: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:317, took 10.554876 s
25/10/26 23:22:14 INFO SparkUI: Stopped Spark web UI at http://t1-11.hpc.icm.edu.pl:4041
25/10/26 23:22:14 INFO Executor: Executor killed task 0.0 in stage 11.0 (TID 29), reason: Stage cancelled: Job aborted due to stage failure: Task 1 in stage 11.0 failed 1 times, most recent failure: Lost task 1.0 in stage 11.0 (TID 30) (t1-11.hpc.icm.edu.pl executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.base/java.lang.Double.valueOf(Double.java:773)
	at net.razorvine.pickle.Unpickler.load_binfloat(Unpickler.java:478)
	at net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:277)
	at net.razorvine.pickle.Unpickler.load(Unpickler.java:109)
	at net.razorvine.pickle.Unpickler.loads(Unpickler.java:122)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$2(BatchEvalPythonExec.scala:67)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec$$Lambda/0x000014a200e96830.apply(Unknown Source)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)
	at org.apache.spark.sql.execution.SparkPlan$$Lambda/0x000014a200ddc000.apply(Unknown Source)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.RDD$$Lambda/0x000014a200d4ee28.apply(Unknown Source)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000014a200911ff0.apply(Unknown Source)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)

Driver stacktrace:
25/10/26 23:22:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/10/26 23:22:14 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks 
java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@31fcb349(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await0(DefaultPromise.java:684)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:300)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:289)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:131)
	at org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)
	at org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:152)
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:151)
	at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:102)
	at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
	at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
	at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
25/10/26 23:22:14 WARN BlockManager: Failed to fetch remote block taskresult_31 from [BlockManagerId(driver, t1-11.hpc.icm.edu.pl, 38785, None)] after 1 fetch failures. Most recent failure cause:
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:103)
	at org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)
	at org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)
	at org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.util.concurrent.ExecutionException: Boxed InterruptedException
	at scala.concurrent.impl.Promise$.resolver(Promise.scala:86)
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:79)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.failure(Promise.scala:104)
	at scala.concurrent.Promise.failure$(Promise.scala:104)
	at scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:187)
	at org.apache.spark.network.BlockTransferService$$anon$1.onBlockFetchFailure(BlockTransferService.scala:83)
	at org.apache.spark.network.shuffle.BlockFetchingListener.onBlockTransferFailure(BlockFetchingListener.java:42)
	at org.apache.spark.network.BlockTransferService$$anon$1.onBlockTransferFailure(BlockTransferService.scala:81)
	at org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:183)
	at org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:152)
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:151)
	at org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:102)
	... 12 more
Caused by: java.lang.InterruptedException: AbstractBootstrap$PendingRegistrationPromise@31fcb349(incomplete)
	at io.netty.util.concurrent.DefaultPromise.await0(DefaultPromise.java:684)
	at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:300)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:289)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:131)
	at org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)
	... 15 more
25/10/26 23:22:14 WARN TaskSetManager: Lost task 2.0 in stage 11.0 (TID 31) (t1-11.hpc.icm.edu.pl executor driver): TaskResultLost (result lost from block manager)
25/10/26 23:22:14 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/10/26 23:22:14 INFO MemoryStore: MemoryStore cleared
25/10/26 23:22:14 INFO BlockManager: BlockManager stopped
25/10/26 23:22:14 INFO BlockManagerMaster: BlockManagerMaster stopped
25/10/26 23:22:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/10/26 23:22:14 INFO SparkContext: Successfully stopped SparkContext
25/10/26 23:22:14 INFO ShutdownHookManager: Shutdown hook called
25/10/26 23:22:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-15623b5f-284c-40ed-b669-edd17c6316aa
25/10/26 23:22:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-7860090e-1dcd-4043-ac35-bfcf20ba8367
25/10/26 23:22:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-15623b5f-284c-40ed-b669-edd17c6316aa/pyspark-3e88d86b-6471-4121-a6ed-961213a2452d
Command exited with non-zero status 52
	Command being timed: "spark-submit --executor-cores 4 minhash.py"
	User time (seconds): 69.03
	System time (seconds): 1.97
	Percent of CPU this job got: 195%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0m 36.30s
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 5860304
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 568
	Minor (reclaiming a frame) page faults: 323756
	Voluntary context switches: 44778
	Involuntary context switches: 14264
	Swaps: 0
	File system inputs: 83056
	File system outputs: 0
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 52
srun: error: t1-11: task 0: Exited with exit code 52
